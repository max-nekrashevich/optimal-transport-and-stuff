{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as t\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "from src.distributions import *\n",
    "from src.loggers import TensorBoardLogger, WandbLogger\n",
    "from src.plotters import ImagePlotter\n",
    "from src.utils import *\n",
    "from src.costs import InnerGW_opt, InnerGW_const\n",
    "from src.models.resnet import resnet14_d, resnet14_g\n",
    "from src.train import train\n",
    "\n",
    "\n",
    "tb_logger = TensorBoardLogger()\n",
    "wandb_logger = WandbLogger(project=\"optimal-transport\",\n",
    "                           entity=\"_devourer_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.set_device(2)\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define source and target distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fc3585c8f174ba390a84f0b0d20e6de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_components = 10\n",
    "locs = 2 * fibonacci_sphere(n_components)\n",
    "scales = .3 * torch.ones_like(locs)\n",
    "source = GaussianMixture(locs, scales, device=DEVICE)\n",
    "\n",
    "features, classes = load_mnist(\"../data/\",\n",
    "                               transform=t.Compose([t.Pad(2), t.ToTensor()]))\n",
    "target = TensorDatasetDistribution(features, classes, device=DEVICE)\n",
    "p, q = source.event_shape.numel(), target.event_shape.numel()\n",
    "\n",
    "U, s, V = torch.pca_lowrank(features.flatten(1), q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [512, 64, 16, 16]           3,136\n",
      "       BatchNorm2d-2          [512, 64, 16, 16]             128\n",
      "         LeakyReLU-3          [512, 64, 16, 16]               0\n",
      "         MaxPool2d-4            [512, 64, 8, 8]               0\n",
      "            Conv2d-5            [512, 64, 8, 8]          36,864\n",
      "       BatchNorm2d-6            [512, 64, 8, 8]             128\n",
      "         LeakyReLU-7            [512, 64, 8, 8]               0\n",
      "            Conv2d-8            [512, 64, 8, 8]          36,864\n",
      "       BatchNorm2d-9            [512, 64, 8, 8]             128\n",
      "     EncoderBlock-10            [512, 64, 8, 8]               0\n",
      "           Conv2d-11            [512, 64, 8, 8]          36,864\n",
      "      BatchNorm2d-12            [512, 64, 8, 8]             128\n",
      "        LeakyReLU-13            [512, 64, 8, 8]               0\n",
      "           Conv2d-14            [512, 64, 8, 8]          36,864\n",
      "      BatchNorm2d-15            [512, 64, 8, 8]             128\n",
      "     EncoderBlock-16            [512, 64, 8, 8]               0\n",
      "           Conv2d-17           [512, 128, 4, 4]          73,728\n",
      "      BatchNorm2d-18           [512, 128, 4, 4]             256\n",
      "        LeakyReLU-19           [512, 128, 4, 4]               0\n",
      "           Conv2d-20           [512, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-21           [512, 128, 4, 4]             256\n",
      "           Conv2d-22           [512, 128, 4, 4]           8,192\n",
      "      BatchNorm2d-23           [512, 128, 4, 4]             256\n",
      "     EncoderBlock-24           [512, 128, 4, 4]               0\n",
      "           Conv2d-25           [512, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-26           [512, 128, 4, 4]             256\n",
      "        LeakyReLU-27           [512, 128, 4, 4]               0\n",
      "           Conv2d-28           [512, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-29           [512, 128, 4, 4]             256\n",
      "     EncoderBlock-30           [512, 128, 4, 4]               0\n",
      "           Conv2d-31           [512, 256, 2, 2]         294,912\n",
      "      BatchNorm2d-32           [512, 256, 2, 2]             512\n",
      "        LeakyReLU-33           [512, 256, 2, 2]               0\n",
      "           Conv2d-34           [512, 256, 2, 2]         589,824\n",
      "      BatchNorm2d-35           [512, 256, 2, 2]             512\n",
      "           Conv2d-36           [512, 256, 2, 2]          32,768\n",
      "      BatchNorm2d-37           [512, 256, 2, 2]             512\n",
      "     EncoderBlock-38           [512, 256, 2, 2]               0\n",
      "           Conv2d-39           [512, 256, 2, 2]         589,824\n",
      "      BatchNorm2d-40           [512, 256, 2, 2]             512\n",
      "        LeakyReLU-41           [512, 256, 2, 2]               0\n",
      "           Conv2d-42           [512, 256, 2, 2]         589,824\n",
      "      BatchNorm2d-43           [512, 256, 2, 2]             512\n",
      "     EncoderBlock-44           [512, 256, 2, 2]               0\n",
      "           Conv2d-45           [512, 512, 1, 1]       1,179,648\n",
      "      BatchNorm2d-46           [512, 512, 1, 1]           1,024\n",
      "        LeakyReLU-47           [512, 512, 1, 1]               0\n",
      "           Conv2d-48           [512, 512, 1, 1]       2,359,296\n",
      "      BatchNorm2d-49           [512, 512, 1, 1]           1,024\n",
      "           Conv2d-50           [512, 512, 1, 1]         131,072\n",
      "      BatchNorm2d-51           [512, 512, 1, 1]           1,024\n",
      "     EncoderBlock-52           [512, 512, 1, 1]               0\n",
      "           Conv2d-53           [512, 512, 1, 1]       2,359,296\n",
      "      BatchNorm2d-54           [512, 512, 1, 1]           1,024\n",
      "        LeakyReLU-55           [512, 512, 1, 1]               0\n",
      "           Conv2d-56           [512, 512, 1, 1]       2,359,296\n",
      "      BatchNorm2d-57           [512, 512, 1, 1]           1,024\n",
      "     EncoderBlock-58           [512, 512, 1, 1]               0\n",
      "        AvgPool2d-59           [512, 512, 1, 1]               0\n",
      "          Flatten-60                 [512, 512]               0\n",
      "           Linear-61                   [512, 1]             513\n",
      "================================================================\n",
      "Total params: 11,170,753\n",
      "Trainable params: 11,170,753\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 2.00\n",
      "Forward/backward pass size (MB): 600.00\n",
      "Params size (MB): 42.61\n",
      "Estimated Total Size (MB): 644.62\n",
      "----------------------------------------------------------------\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                 [512, 512]           2,048\n",
      "         Unflatten-2           [512, 512, 1, 1]               0\n",
      "          Upsample-3           [512, 512, 1, 1]               0\n",
      "            Conv2d-4           [512, 512, 1, 1]       2,359,296\n",
      "       BatchNorm2d-5           [512, 512, 1, 1]           1,024\n",
      "         LeakyReLU-6           [512, 512, 1, 1]               0\n",
      "          Upsample-7           [512, 512, 1, 1]               0\n",
      "            Conv2d-8           [512, 512, 1, 1]       2,359,296\n",
      "       BatchNorm2d-9           [512, 512, 1, 1]           1,024\n",
      "     DecoderBlock-10           [512, 512, 1, 1]               0\n",
      "           Conv2d-11           [512, 512, 1, 1]       2,359,296\n",
      "      BatchNorm2d-12           [512, 512, 1, 1]           1,024\n",
      "        LeakyReLU-13           [512, 512, 1, 1]               0\n",
      "         Upsample-14           [512, 512, 2, 2]               0\n",
      "           Conv2d-15           [512, 256, 2, 2]       1,179,648\n",
      "      BatchNorm2d-16           [512, 256, 2, 2]             512\n",
      "         Upsample-17           [512, 512, 2, 2]               0\n",
      "           Conv2d-18           [512, 256, 2, 2]         131,072\n",
      "      BatchNorm2d-19           [512, 256, 2, 2]             512\n",
      "     DecoderBlock-20           [512, 256, 2, 2]               0\n",
      "           Conv2d-21           [512, 256, 2, 2]         589,824\n",
      "      BatchNorm2d-22           [512, 256, 2, 2]             512\n",
      "        LeakyReLU-23           [512, 256, 2, 2]               0\n",
      "         Upsample-24           [512, 256, 2, 2]               0\n",
      "           Conv2d-25           [512, 256, 2, 2]         589,824\n",
      "      BatchNorm2d-26           [512, 256, 2, 2]             512\n",
      "     DecoderBlock-27           [512, 256, 2, 2]               0\n",
      "           Conv2d-28           [512, 256, 2, 2]         589,824\n",
      "      BatchNorm2d-29           [512, 256, 2, 2]             512\n",
      "        LeakyReLU-30           [512, 256, 2, 2]               0\n",
      "         Upsample-31           [512, 256, 4, 4]               0\n",
      "           Conv2d-32           [512, 128, 4, 4]         294,912\n",
      "      BatchNorm2d-33           [512, 128, 4, 4]             256\n",
      "         Upsample-34           [512, 256, 4, 4]               0\n",
      "           Conv2d-35           [512, 128, 4, 4]          32,768\n",
      "      BatchNorm2d-36           [512, 128, 4, 4]             256\n",
      "     DecoderBlock-37           [512, 128, 4, 4]               0\n",
      "           Conv2d-38           [512, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-39           [512, 128, 4, 4]             256\n",
      "        LeakyReLU-40           [512, 128, 4, 4]               0\n",
      "         Upsample-41           [512, 128, 4, 4]               0\n",
      "           Conv2d-42           [512, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-43           [512, 128, 4, 4]             256\n",
      "     DecoderBlock-44           [512, 128, 4, 4]               0\n",
      "           Conv2d-45           [512, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-46           [512, 128, 4, 4]             256\n",
      "        LeakyReLU-47           [512, 128, 4, 4]               0\n",
      "         Upsample-48           [512, 128, 8, 8]               0\n",
      "           Conv2d-49            [512, 64, 8, 8]          73,728\n",
      "      BatchNorm2d-50            [512, 64, 8, 8]             128\n",
      "         Upsample-51           [512, 128, 8, 8]               0\n",
      "           Conv2d-52            [512, 64, 8, 8]           8,192\n",
      "      BatchNorm2d-53            [512, 64, 8, 8]             128\n",
      "     DecoderBlock-54            [512, 64, 8, 8]               0\n",
      "           Conv2d-55            [512, 64, 8, 8]          36,864\n",
      "      BatchNorm2d-56            [512, 64, 8, 8]             128\n",
      "        LeakyReLU-57            [512, 64, 8, 8]               0\n",
      "         Upsample-58            [512, 64, 8, 8]               0\n",
      "           Conv2d-59            [512, 64, 8, 8]          36,864\n",
      "      BatchNorm2d-60            [512, 64, 8, 8]             128\n",
      "     DecoderBlock-61            [512, 64, 8, 8]               0\n",
      "           Conv2d-62            [512, 64, 8, 8]          36,864\n",
      "      BatchNorm2d-63            [512, 64, 8, 8]             128\n",
      "        LeakyReLU-64            [512, 64, 8, 8]               0\n",
      "         Upsample-65            [512, 64, 8, 8]               0\n",
      "           Conv2d-66            [512, 64, 8, 8]          36,864\n",
      "      BatchNorm2d-67            [512, 64, 8, 8]             128\n",
      "     DecoderBlock-68            [512, 64, 8, 8]               0\n",
      "         Upsample-69          [512, 64, 16, 16]               0\n",
      "  ConvTranspose2d-70           [512, 1, 32, 32]           4,096\n",
      "      BatchNorm2d-71           [512, 1, 32, 32]               2\n",
      "          Sigmoid-72           [512, 1, 32, 32]               0\n",
      "================================================================\n",
      "Total params: 11,171,330\n",
      "Trainable params: 11,171,330\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 698.00\n",
      "Params size (MB): 42.62\n",
      "Estimated Total Size (MB): 740.62\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "n_neurons = 128\n",
    "\n",
    "critic = resnet18_d(target.event_shape).to(DEVICE)\n",
    "summary(critic, target.event_shape, batch_size=512)\n",
    "\n",
    "mover = resnet18_g(target.event_shape, p).to(DEVICE)\n",
    "summary(mover, (p,), batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(source, target, mover, critic, cost, n_iter, *,\n",
    "                   logger=None, **kwargs):\n",
    "    if logger: \n",
    "        logger.start()\n",
    "        logger.log_hparams(kwargs)\n",
    "    try:\n",
    "        train(source, target, mover, critic, cost,\n",
    "              n_iter=n_iter,\n",
    "              logger=logger,\n",
    "              **kwargs)\n",
    "    except KeyboardInterrupt:\n",
    "        pass\n",
    "    finally:\n",
    "        if logger: logger.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/mounted/optimal-transport-and-stuff/notebooks/wandb/run-20220316_143543-3qcwffp0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/_devourer_/optimal-transport/runs/3qcwffp0\" target=\"_blank\">desert-dust-116</a></strong> to <a href=\"https://wandb.ai/_devourer_/optimal-transport\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0aaaf3559b364201a9aee7422087b092",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70ad80464db948cb93cbebf73bd231ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_experiment(\n",
    "    source, target, *copy_models(mover, critic),\n",
    "    n_iter=5000,\n",
    "    n_samples=512,\n",
    "    cost=InnerGW_opt(p, q,\n",
    "        optimizer_params=dict(lr=2e-4, weight_decay=1e-10),\n",
    "        n_iter=10,\n",
    "        device=DEVICE\n",
    "    ),\n",
    "    # cost=InnerGW_const(V.to(DEVICE)),\n",
    "    plotter=ImagePlotter(plot_interval=100, n_images=20, n_samples=2),\n",
    "    logger=wandb_logger,\n",
    "    n_iter_mover=5,\n",
    "    optimizer_params=dict(lr=1e-5, weight_decay=1e-10),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ff4d7889a3e633245f6f5289845f79fcb0cbba3c688731bf4887729c825c107a"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
