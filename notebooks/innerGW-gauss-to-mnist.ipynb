{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as t\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "from src.distributions import *\n",
    "from src.loggers import TensorBoardLogger, WandbLogger\n",
    "from src.plotters import ImagePlotter\n",
    "from src.utils import *\n",
    "from src.costs import InnerGW_opt, InnerGW_const\n",
    "from src.models.resnet import resnet18_d, resnet18_g\n",
    "from src.train import train\n",
    "\n",
    "\n",
    "tb_logger = TensorBoardLogger()\n",
    "wandb_logger = WandbLogger(project=\"optimal-transport\",\n",
    "                           entity=\"_devourer_\",\n",
    "                           mode=\"offline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.set_device(2)\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define source and target distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2935aeb7258542599cb9994ce5de4b63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_components = 10\n",
    "locs = 2 * uniform_circle(n_components)\n",
    "scales = .3 * torch.ones_like(locs)\n",
    "source = GaussianMixture(locs, scales, device=DEVICE)\n",
    "\n",
    "features, classes = load_mnist(\"../data/\",\n",
    "                               transform=t.Compose([t.Pad(2), t.ToTensor()]))\n",
    "target = TensorDatasetDistribution(features, classes, device=DEVICE)\n",
    "p, q = source.event_shape.numel(), target.event_shape.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [512, 64, 16, 16]           3,136\n",
      "       BatchNorm2d-2          [512, 64, 16, 16]             128\n",
      "         LeakyReLU-3          [512, 64, 16, 16]               0\n",
      "         MaxPool2d-4            [512, 64, 8, 8]               0\n",
      "            Conv2d-5            [512, 64, 8, 8]          36,864\n",
      "       BatchNorm2d-6            [512, 64, 8, 8]             128\n",
      "         LeakyReLU-7            [512, 64, 8, 8]               0\n",
      "            Conv2d-8            [512, 64, 8, 8]          36,864\n",
      "       BatchNorm2d-9            [512, 64, 8, 8]             128\n",
      "     EncoderBlock-10            [512, 64, 8, 8]               0\n",
      "           Conv2d-11            [512, 64, 8, 8]          36,864\n",
      "      BatchNorm2d-12            [512, 64, 8, 8]             128\n",
      "        LeakyReLU-13            [512, 64, 8, 8]               0\n",
      "           Conv2d-14            [512, 64, 8, 8]          36,864\n",
      "      BatchNorm2d-15            [512, 64, 8, 8]             128\n",
      "     EncoderBlock-16            [512, 64, 8, 8]               0\n",
      "           Conv2d-17           [512, 128, 4, 4]          73,728\n",
      "      BatchNorm2d-18           [512, 128, 4, 4]             256\n",
      "        LeakyReLU-19           [512, 128, 4, 4]               0\n",
      "           Conv2d-20           [512, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-21           [512, 128, 4, 4]             256\n",
      "           Conv2d-22           [512, 128, 4, 4]           8,192\n",
      "      BatchNorm2d-23           [512, 128, 4, 4]             256\n",
      "     EncoderBlock-24           [512, 128, 4, 4]               0\n",
      "           Conv2d-25           [512, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-26           [512, 128, 4, 4]             256\n",
      "        LeakyReLU-27           [512, 128, 4, 4]               0\n",
      "           Conv2d-28           [512, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-29           [512, 128, 4, 4]             256\n",
      "     EncoderBlock-30           [512, 128, 4, 4]               0\n",
      "           Conv2d-31           [512, 256, 2, 2]         294,912\n",
      "      BatchNorm2d-32           [512, 256, 2, 2]             512\n",
      "        LeakyReLU-33           [512, 256, 2, 2]               0\n",
      "           Conv2d-34           [512, 256, 2, 2]         589,824\n",
      "      BatchNorm2d-35           [512, 256, 2, 2]             512\n",
      "           Conv2d-36           [512, 256, 2, 2]          32,768\n",
      "      BatchNorm2d-37           [512, 256, 2, 2]             512\n",
      "     EncoderBlock-38           [512, 256, 2, 2]               0\n",
      "           Conv2d-39           [512, 256, 2, 2]         589,824\n",
      "      BatchNorm2d-40           [512, 256, 2, 2]             512\n",
      "        LeakyReLU-41           [512, 256, 2, 2]               0\n",
      "           Conv2d-42           [512, 256, 2, 2]         589,824\n",
      "      BatchNorm2d-43           [512, 256, 2, 2]             512\n",
      "     EncoderBlock-44           [512, 256, 2, 2]               0\n",
      "           Conv2d-45           [512, 512, 1, 1]       1,179,648\n",
      "      BatchNorm2d-46           [512, 512, 1, 1]           1,024\n",
      "        LeakyReLU-47           [512, 512, 1, 1]               0\n",
      "           Conv2d-48           [512, 512, 1, 1]       2,359,296\n",
      "      BatchNorm2d-49           [512, 512, 1, 1]           1,024\n",
      "           Conv2d-50           [512, 512, 1, 1]         131,072\n",
      "      BatchNorm2d-51           [512, 512, 1, 1]           1,024\n",
      "     EncoderBlock-52           [512, 512, 1, 1]               0\n",
      "           Conv2d-53           [512, 512, 1, 1]       2,359,296\n",
      "      BatchNorm2d-54           [512, 512, 1, 1]           1,024\n",
      "        LeakyReLU-55           [512, 512, 1, 1]               0\n",
      "           Conv2d-56           [512, 512, 1, 1]       2,359,296\n",
      "      BatchNorm2d-57           [512, 512, 1, 1]           1,024\n",
      "     EncoderBlock-58           [512, 512, 1, 1]               0\n",
      "        AvgPool2d-59           [512, 512, 1, 1]               0\n",
      "          Flatten-60                 [512, 512]               0\n",
      "           Linear-61                   [512, 1]             513\n",
      "================================================================\n",
      "Total params: 11,170,753\n",
      "Trainable params: 11,170,753\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 2.00\n",
      "Forward/backward pass size (MB): 600.00\n",
      "Params size (MB): 42.61\n",
      "Estimated Total Size (MB): 644.62\n",
      "----------------------------------------------------------------\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                 [512, 512]           1,536\n",
      "         Unflatten-2           [512, 512, 1, 1]               0\n",
      "          Upsample-3           [512, 512, 1, 1]               0\n",
      "            Conv2d-4           [512, 512, 1, 1]       2,359,296\n",
      "       BatchNorm2d-5           [512, 512, 1, 1]           1,024\n",
      "         LeakyReLU-6           [512, 512, 1, 1]               0\n",
      "          Upsample-7           [512, 512, 1, 1]               0\n",
      "            Conv2d-8           [512, 512, 1, 1]       2,359,296\n",
      "       BatchNorm2d-9           [512, 512, 1, 1]           1,024\n",
      "     DecoderBlock-10           [512, 512, 1, 1]               0\n",
      "           Conv2d-11           [512, 512, 1, 1]       2,359,296\n",
      "      BatchNorm2d-12           [512, 512, 1, 1]           1,024\n",
      "        LeakyReLU-13           [512, 512, 1, 1]               0\n",
      "         Upsample-14           [512, 512, 2, 2]               0\n",
      "           Conv2d-15           [512, 256, 2, 2]       1,179,648\n",
      "      BatchNorm2d-16           [512, 256, 2, 2]             512\n",
      "         Upsample-17           [512, 512, 2, 2]               0\n",
      "           Conv2d-18           [512, 256, 2, 2]         131,072\n",
      "      BatchNorm2d-19           [512, 256, 2, 2]             512\n",
      "     DecoderBlock-20           [512, 256, 2, 2]               0\n",
      "           Conv2d-21           [512, 256, 2, 2]         589,824\n",
      "      BatchNorm2d-22           [512, 256, 2, 2]             512\n",
      "        LeakyReLU-23           [512, 256, 2, 2]               0\n",
      "         Upsample-24           [512, 256, 2, 2]               0\n",
      "           Conv2d-25           [512, 256, 2, 2]         589,824\n",
      "      BatchNorm2d-26           [512, 256, 2, 2]             512\n",
      "     DecoderBlock-27           [512, 256, 2, 2]               0\n",
      "           Conv2d-28           [512, 256, 2, 2]         589,824\n",
      "      BatchNorm2d-29           [512, 256, 2, 2]             512\n",
      "        LeakyReLU-30           [512, 256, 2, 2]               0\n",
      "         Upsample-31           [512, 256, 4, 4]               0\n",
      "           Conv2d-32           [512, 128, 4, 4]         294,912\n",
      "      BatchNorm2d-33           [512, 128, 4, 4]             256\n",
      "         Upsample-34           [512, 256, 4, 4]               0\n",
      "           Conv2d-35           [512, 128, 4, 4]          32,768\n",
      "      BatchNorm2d-36           [512, 128, 4, 4]             256\n",
      "     DecoderBlock-37           [512, 128, 4, 4]               0\n",
      "           Conv2d-38           [512, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-39           [512, 128, 4, 4]             256\n",
      "        LeakyReLU-40           [512, 128, 4, 4]               0\n",
      "         Upsample-41           [512, 128, 4, 4]               0\n",
      "           Conv2d-42           [512, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-43           [512, 128, 4, 4]             256\n",
      "     DecoderBlock-44           [512, 128, 4, 4]               0\n",
      "           Conv2d-45           [512, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-46           [512, 128, 4, 4]             256\n",
      "        LeakyReLU-47           [512, 128, 4, 4]               0\n",
      "         Upsample-48           [512, 128, 8, 8]               0\n",
      "           Conv2d-49            [512, 64, 8, 8]          73,728\n",
      "      BatchNorm2d-50            [512, 64, 8, 8]             128\n",
      "         Upsample-51           [512, 128, 8, 8]               0\n",
      "           Conv2d-52            [512, 64, 8, 8]           8,192\n",
      "      BatchNorm2d-53            [512, 64, 8, 8]             128\n",
      "     DecoderBlock-54            [512, 64, 8, 8]               0\n",
      "           Conv2d-55            [512, 64, 8, 8]          36,864\n",
      "      BatchNorm2d-56            [512, 64, 8, 8]             128\n",
      "        LeakyReLU-57            [512, 64, 8, 8]               0\n",
      "         Upsample-58            [512, 64, 8, 8]               0\n",
      "           Conv2d-59            [512, 64, 8, 8]          36,864\n",
      "      BatchNorm2d-60            [512, 64, 8, 8]             128\n",
      "     DecoderBlock-61            [512, 64, 8, 8]               0\n",
      "           Conv2d-62            [512, 64, 8, 8]          36,864\n",
      "      BatchNorm2d-63            [512, 64, 8, 8]             128\n",
      "        LeakyReLU-64            [512, 64, 8, 8]               0\n",
      "         Upsample-65            [512, 64, 8, 8]               0\n",
      "           Conv2d-66            [512, 64, 8, 8]          36,864\n",
      "      BatchNorm2d-67            [512, 64, 8, 8]             128\n",
      "     DecoderBlock-68            [512, 64, 8, 8]               0\n",
      "         Upsample-69          [512, 64, 16, 16]               0\n",
      "  ConvTranspose2d-70           [512, 1, 32, 32]           4,096\n",
      "      BatchNorm2d-71           [512, 1, 32, 32]               2\n",
      "          Sigmoid-72           [512, 1, 32, 32]               0\n",
      "================================================================\n",
      "Total params: 11,170,818\n",
      "Trainable params: 11,170,818\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 698.00\n",
      "Params size (MB): 42.61\n",
      "Estimated Total Size (MB): 740.62\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "n_neurons = 128\n",
    "\n",
    "critic = resnet18_d(target.event_shape).to(DEVICE)\n",
    "summary(critic, target.event_shape, batch_size=512)\n",
    "\n",
    "mover = resnet18_g(target.event_shape, p).to(DEVICE)\n",
    "summary(mover, (p,), batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(source, target, mover, critic, cost, n_iter, *,\n",
    "                   logger=None, **kwargs):\n",
    "    if logger: logger.start()\n",
    "    try:\n",
    "        train(source, target, mover, critic, cost,\n",
    "              n_iter=n_iter,\n",
    "              logger=logger,\n",
    "              **kwargs)\n",
    "    except KeyboardInterrupt:\n",
    "        pass\n",
    "    finally:\n",
    "        if logger: logger.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B syncing is set to <code>`offline`<code> in this directory.  <br/>Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f8185ad78df4735987cc4ba745de853",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9965d0e5bc93455c9a900953ee67a2ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.000 MB of 0.000 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, maxâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "You can sync this run to the cloud by running:<br/><code>wandb sync /home/mounted/optimal-transport-and-stuff/notebooks/wandb/offline-run-20220310_133119-1rljw8xv<code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/offline-run-20220310_133119-1rljw8xv/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'interrupted' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [28]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mrun_experiment\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcopy_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmover\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcritic\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcost\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mInnerGW_opt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2e-5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-10\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDEVICE\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# cost=InnerGW_const(V.to(DEVICE)),\u001b[39;49;00m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mplotter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mImagePlotter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mplot_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_images\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogger\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwandb_logger\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_iter_mover\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2e-5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-10\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [21]\u001b[0m, in \u001b[0;36mrun_experiment\u001b[0;34m(source, target, mover, critic, cost, n_iter, logger, **kwargs)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m logger: logger\u001b[38;5;241m.\u001b[39mstart()\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m----> 5\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmover\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcritic\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcost\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m          \u001b[49m\u001b[43mn_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m          \u001b[49m\u001b[43mlogger\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogger\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m          \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m/home/mounted/optimal-transport-and-stuff/src/train.py:45\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(source, target, mover, critic, cost_func, n_iter, n_samples, n_iter_mover, n_iter_critic, optimizer, optimizer_params, logger, plotter, progress_bar)\u001b[0m\n\u001b[1;32m     42\u001b[0m     critic_optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m plotter:\n\u001b[0;32m---> 45\u001b[0m     figure \u001b[38;5;241m=\u001b[39m \u001b[43mplotter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcritic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcritic\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m     _log(logger, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTransport\u001b[39m\u001b[38;5;124m\"\u001b[39m, figure, advance\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, close\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "File \u001b[0;32m/home/mounted/optimal-transport-and-stuff/src/plotters/__init__.py:58\u001b[0m, in \u001b[0;36mPlotter.plot_step\u001b[0;34m(self, x, y, h_x, labels, critic)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_widget\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m     56\u001b[0m         interrupted \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43minterrupted\u001b[49m:\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m figure\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'interrupted' referenced before assignment"
     ]
    }
   ],
   "source": [
    "run_experiment(\n",
    "    source, target, *copy_models(mover, critic),\n",
    "    n_iter=4000,\n",
    "    n_samples=512,\n",
    "    cost=InnerGW_opt(p, q,\n",
    "        optimizer_params=dict(lr=2e-5, weight_decay=1e-10),\n",
    "        n_iter=2,\n",
    "        device=DEVICE\n",
    "    ),\n",
    "    # cost=InnerGW_const(V.to(DEVICE)),\n",
    "    plotter=ImagePlotter(plot_interval=100, n_images=10),\n",
    "    logger=wandb_logger,\n",
    "    n_iter_mover=2,\n",
    "    optimizer_params=dict(lr=2e-5, weight_decay=1e-10),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ff4d7889a3e633245f6f5289845f79fcb0cbba3c688731bf4887729c825c107a"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
