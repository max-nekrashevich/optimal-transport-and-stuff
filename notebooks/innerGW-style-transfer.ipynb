{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as t\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "from src.distributions import *\n",
    "from src.loggers import TensorBoardLogger, WandbLogger\n",
    "from src.plotters import ImagePlotter\n",
    "from src.utils import *\n",
    "from src.costs import InnerGW_conv\n",
    "from src.models.resnet import resnet18_d\n",
    "from src.models.unet import unet_h\n",
    "from src.train import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    torch.cuda.set_device(2)\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "tb_logger = TensorBoardLogger()\n",
    "wandb_logger = WandbLogger(project=\"optimal-transport\",\n",
    "                           entity=\"_devourer_\",\n",
    "                           mode=\"offline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fe06603842343f0856ed8f59908cc89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50025 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0e3d6f594a84ca1b46b9e5e851ac9e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/138767 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "shoes = load_h5py(\"../data/shoes_64.hdf5\",\n",
    "                  transform=t.Compose([t.ToTensor(), t.Resize(32)]))\n",
    "source = TensorDatasetDistribution(shoes, torch.zeros(shoes.size(0)), device=DEVICE)\n",
    "handbag = load_h5py(\"../data/handbag_64.hdf5\",\n",
    "                    transform=t.Compose([t.ToTensor(), t.Resize(32)]))\n",
    "target = TensorDatasetDistribution(handbag, torch.zeros(handbag.size(0)), device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [512, 64, 16, 16]           9,408\n",
      "       BatchNorm2d-2          [512, 64, 16, 16]             128\n",
      "         LeakyReLU-3          [512, 64, 16, 16]               0\n",
      "         MaxPool2d-4            [512, 64, 8, 8]               0\n",
      "            Conv2d-5            [512, 64, 8, 8]          36,864\n",
      "       BatchNorm2d-6            [512, 64, 8, 8]             128\n",
      "         LeakyReLU-7            [512, 64, 8, 8]               0\n",
      "            Conv2d-8            [512, 64, 8, 8]          36,864\n",
      "       BatchNorm2d-9            [512, 64, 8, 8]             128\n",
      "     EncoderBlock-10            [512, 64, 8, 8]               0\n",
      "           Conv2d-11            [512, 64, 8, 8]          36,864\n",
      "      BatchNorm2d-12            [512, 64, 8, 8]             128\n",
      "        LeakyReLU-13            [512, 64, 8, 8]               0\n",
      "           Conv2d-14            [512, 64, 8, 8]          36,864\n",
      "      BatchNorm2d-15            [512, 64, 8, 8]             128\n",
      "     EncoderBlock-16            [512, 64, 8, 8]               0\n",
      "           Conv2d-17           [512, 128, 4, 4]          73,728\n",
      "      BatchNorm2d-18           [512, 128, 4, 4]             256\n",
      "        LeakyReLU-19           [512, 128, 4, 4]               0\n",
      "           Conv2d-20           [512, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-21           [512, 128, 4, 4]             256\n",
      "           Conv2d-22           [512, 128, 4, 4]           8,192\n",
      "      BatchNorm2d-23           [512, 128, 4, 4]             256\n",
      "     EncoderBlock-24           [512, 128, 4, 4]               0\n",
      "           Conv2d-25           [512, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-26           [512, 128, 4, 4]             256\n",
      "        LeakyReLU-27           [512, 128, 4, 4]               0\n",
      "           Conv2d-28           [512, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-29           [512, 128, 4, 4]             256\n",
      "     EncoderBlock-30           [512, 128, 4, 4]               0\n",
      "           Conv2d-31           [512, 256, 2, 2]         294,912\n",
      "      BatchNorm2d-32           [512, 256, 2, 2]             512\n",
      "        LeakyReLU-33           [512, 256, 2, 2]               0\n",
      "           Conv2d-34           [512, 256, 2, 2]         589,824\n",
      "      BatchNorm2d-35           [512, 256, 2, 2]             512\n",
      "           Conv2d-36           [512, 256, 2, 2]          32,768\n",
      "      BatchNorm2d-37           [512, 256, 2, 2]             512\n",
      "     EncoderBlock-38           [512, 256, 2, 2]               0\n",
      "           Conv2d-39           [512, 256, 2, 2]         589,824\n",
      "      BatchNorm2d-40           [512, 256, 2, 2]             512\n",
      "        LeakyReLU-41           [512, 256, 2, 2]               0\n",
      "           Conv2d-42           [512, 256, 2, 2]         589,824\n",
      "      BatchNorm2d-43           [512, 256, 2, 2]             512\n",
      "     EncoderBlock-44           [512, 256, 2, 2]               0\n",
      "           Conv2d-45           [512, 512, 1, 1]       1,179,648\n",
      "      BatchNorm2d-46           [512, 512, 1, 1]           1,024\n",
      "        LeakyReLU-47           [512, 512, 1, 1]               0\n",
      "           Conv2d-48           [512, 512, 1, 1]       2,359,296\n",
      "      BatchNorm2d-49           [512, 512, 1, 1]           1,024\n",
      "           Conv2d-50           [512, 512, 1, 1]         131,072\n",
      "      BatchNorm2d-51           [512, 512, 1, 1]           1,024\n",
      "     EncoderBlock-52           [512, 512, 1, 1]               0\n",
      "           Conv2d-53           [512, 512, 1, 1]       2,359,296\n",
      "      BatchNorm2d-54           [512, 512, 1, 1]           1,024\n",
      "        LeakyReLU-55           [512, 512, 1, 1]               0\n",
      "           Conv2d-56           [512, 512, 1, 1]       2,359,296\n",
      "      BatchNorm2d-57           [512, 512, 1, 1]           1,024\n",
      "     EncoderBlock-58           [512, 512, 1, 1]               0\n",
      "        AvgPool2d-59           [512, 512, 1, 1]               0\n",
      "          Flatten-60                 [512, 512]               0\n",
      "           Linear-61                   [512, 1]             513\n",
      "================================================================\n",
      "Total params: 11,177,025\n",
      "Trainable params: 11,177,025\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 6.00\n",
      "Forward/backward pass size (MB): 600.00\n",
      "Params size (MB): 42.64\n",
      "Estimated Total Size (MB): 648.64\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "critic = resnet18_d(target.event_shape).to(DEVICE)\n",
    "summary(critic, target.event_shape, batch_size=512, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [512, 32, 32, 32]             864\n",
      "       BatchNorm2d-2          [512, 32, 32, 32]              64\n",
      "              ReLU-3          [512, 32, 32, 32]               0\n",
      "            Conv2d-4          [512, 32, 32, 32]           9,216\n",
      "       BatchNorm2d-5          [512, 32, 32, 32]              64\n",
      "              ReLU-6          [512, 32, 32, 32]               0\n",
      "        DoubleConv-7          [512, 32, 32, 32]               0\n",
      "         MaxPool2d-8          [512, 32, 16, 16]               0\n",
      "            Conv2d-9          [512, 64, 16, 16]          18,432\n",
      "      BatchNorm2d-10          [512, 64, 16, 16]             128\n",
      "             ReLU-11          [512, 64, 16, 16]               0\n",
      "           Conv2d-12          [512, 64, 16, 16]          36,864\n",
      "      BatchNorm2d-13          [512, 64, 16, 16]             128\n",
      "             ReLU-14          [512, 64, 16, 16]               0\n",
      "       DoubleConv-15          [512, 64, 16, 16]               0\n",
      "             Down-16          [512, 64, 16, 16]               0\n",
      "        MaxPool2d-17            [512, 64, 8, 8]               0\n",
      "           Conv2d-18           [512, 128, 8, 8]          73,728\n",
      "      BatchNorm2d-19           [512, 128, 8, 8]             256\n",
      "             ReLU-20           [512, 128, 8, 8]               0\n",
      "           Conv2d-21           [512, 128, 8, 8]         147,456\n",
      "      BatchNorm2d-22           [512, 128, 8, 8]             256\n",
      "             ReLU-23           [512, 128, 8, 8]               0\n",
      "       DoubleConv-24           [512, 128, 8, 8]               0\n",
      "             Down-25           [512, 128, 8, 8]               0\n",
      "        MaxPool2d-26           [512, 128, 4, 4]               0\n",
      "           Conv2d-27           [512, 256, 4, 4]         294,912\n",
      "      BatchNorm2d-28           [512, 256, 4, 4]             512\n",
      "             ReLU-29           [512, 256, 4, 4]               0\n",
      "           Conv2d-30           [512, 256, 4, 4]         589,824\n",
      "      BatchNorm2d-31           [512, 256, 4, 4]             512\n",
      "             ReLU-32           [512, 256, 4, 4]               0\n",
      "       DoubleConv-33           [512, 256, 4, 4]               0\n",
      "             Down-34           [512, 256, 4, 4]               0\n",
      "        MaxPool2d-35           [512, 256, 2, 2]               0\n",
      "           Conv2d-36           [512, 256, 2, 2]         589,824\n",
      "      BatchNorm2d-37           [512, 256, 2, 2]             512\n",
      "             ReLU-38           [512, 256, 2, 2]               0\n",
      "           Conv2d-39           [512, 256, 2, 2]         589,824\n",
      "      BatchNorm2d-40           [512, 256, 2, 2]             512\n",
      "             ReLU-41           [512, 256, 2, 2]               0\n",
      "       DoubleConv-42           [512, 256, 2, 2]               0\n",
      "             Down-43           [512, 256, 2, 2]               0\n",
      "         Upsample-44           [512, 256, 4, 4]               0\n",
      "           Conv2d-45           [512, 256, 4, 4]       1,179,648\n",
      "      BatchNorm2d-46           [512, 256, 4, 4]             512\n",
      "             ReLU-47           [512, 256, 4, 4]               0\n",
      "           Conv2d-48           [512, 128, 4, 4]         294,912\n",
      "      BatchNorm2d-49           [512, 128, 4, 4]             256\n",
      "             ReLU-50           [512, 128, 4, 4]               0\n",
      "       DoubleConv-51           [512, 128, 4, 4]               0\n",
      "               Up-52           [512, 128, 4, 4]               0\n",
      "         Upsample-53           [512, 128, 8, 8]               0\n",
      "           Conv2d-54           [512, 128, 8, 8]         294,912\n",
      "      BatchNorm2d-55           [512, 128, 8, 8]             256\n",
      "             ReLU-56           [512, 128, 8, 8]               0\n",
      "           Conv2d-57            [512, 64, 8, 8]          73,728\n",
      "      BatchNorm2d-58            [512, 64, 8, 8]             128\n",
      "             ReLU-59            [512, 64, 8, 8]               0\n",
      "       DoubleConv-60            [512, 64, 8, 8]               0\n",
      "               Up-61            [512, 64, 8, 8]               0\n",
      "         Upsample-62          [512, 64, 16, 16]               0\n",
      "           Conv2d-63          [512, 64, 16, 16]          73,728\n",
      "      BatchNorm2d-64          [512, 64, 16, 16]             128\n",
      "             ReLU-65          [512, 64, 16, 16]               0\n",
      "           Conv2d-66          [512, 32, 16, 16]          18,432\n",
      "      BatchNorm2d-67          [512, 32, 16, 16]              64\n",
      "             ReLU-68          [512, 32, 16, 16]               0\n",
      "       DoubleConv-69          [512, 32, 16, 16]               0\n",
      "               Up-70          [512, 32, 16, 16]               0\n",
      "         Upsample-71          [512, 32, 32, 32]               0\n",
      "           Conv2d-72          [512, 32, 32, 32]          18,432\n",
      "      BatchNorm2d-73          [512, 32, 32, 32]              64\n",
      "             ReLU-74          [512, 32, 32, 32]               0\n",
      "           Conv2d-75          [512, 32, 32, 32]           9,216\n",
      "      BatchNorm2d-76          [512, 32, 32, 32]              64\n",
      "             ReLU-77          [512, 32, 32, 32]               0\n",
      "       DoubleConv-78          [512, 32, 32, 32]               0\n",
      "               Up-79          [512, 32, 32, 32]               0\n",
      "           Conv2d-80           [512, 3, 32, 32]              99\n",
      "          OutConv-81           [512, 3, 32, 32]               0\n",
      "================================================================\n",
      "Total params: 4,318,467\n",
      "Trainable params: 4,318,467\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 6.00\n",
      "Forward/backward pass size (MB): 3788.00\n",
      "Params size (MB): 16.47\n",
      "Estimated Total Size (MB): 3810.47\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "mover = unet_h(source.event_shape, base_channels=32).to(DEVICE)\n",
    "summary(mover, source.event_shape, batch_size=512, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(source, target, mover, critic, cost, n_iter, *,\n",
    "                   logger=None, **kwargs):\n",
    "    if logger: \n",
    "        logger.start()\n",
    "        logger.log_hparams(kwargs)\n",
    "    try:\n",
    "        train(source, target, mover, critic, cost,\n",
    "              n_iter=n_iter,\n",
    "              logger=logger,\n",
    "              **kwargs)\n",
    "    except KeyboardInterrupt:\n",
    "        pass\n",
    "    finally:\n",
    "        if logger: logger.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B syncing is set to <code>`offline`<code> in this directory.  <br/>Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d378df92ea474be5bab5880918be570e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d69b466a5af485f88718b062360685e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f93d5f027944d4b89690a2fa7d0f52d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.000 MB of 0.000 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>cost</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>cost</td><td>550466.0</td></tr><tr><td>loss</td><td>550466.75</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "You can sync this run to the cloud by running:<br/><code>wandb sync /home/max/optimal-transport-and-stuff/notebooks/wandb/offline-run-20220318_150926-1ihiwop4<code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/offline-run-20220318_150926-1ihiwop4/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_experiment(\n",
    "    source, target, *copy_models(mover, critic),\n",
    "    n_iter=5000,\n",
    "    n_samples=128,\n",
    "    cost=InnerGW_conv(\n",
    "        optimizer_params=dict(lr=1e-3, weight_decay=1e-10),\n",
    "        n_iter=10,\n",
    "        device=DEVICE\n",
    "    ),\n",
    "    plotter=ImagePlotter(plot_interval=100, n_images=20, n_samples=2, plot_source=False),\n",
    "    logger=wandb_logger,\n",
    "    n_iter_mover=5,\n",
    "    optimizer_params=dict(lr=1e-4, weight_decay=1e-10),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ff4d7889a3e633245f6f5289845f79fcb0cbba3c688731bf4887729c825c107a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
